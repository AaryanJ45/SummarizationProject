{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing langchain and other dependencies needed"
      ],
      "metadata": {
        "id": "mI219vqCmolL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRywrCNfmTvU"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet tiktoken langchain langgraph beautifulsoup4 langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step loads in our documents. I'm going to load in a blog from a website."
      ],
      "metadata": {
        "id": "iDKXt9sCM1ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://www.atlassian.com/blog/artificial-intelligence/artificial-intelligence-101-the-basics-of-ai\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "jFlERJaaNBOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing and setting up the model"
      ],
      "metadata": {
        "id": "MkJQBNRROHiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU \"langchain[google-genai]\""
      ],
      "metadata": {
        "id": "p7Bbgs4MNvHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"gemini-2.0-flash\", model_provider = \"google_genai\")"
      ],
      "metadata": {
        "id": "B9iaWSAMch2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stuff**:\n",
        "Summarizing in a single LLM call\n",
        "\n",
        "create_stuff_documents_chain() - The chain will take a list of documents, insert them all into a prompt, and pass that prompt to an LLM."
      ],
      "metadata": {
        "id": "7TtekX3ueL9K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9FBpjYYReSDo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
